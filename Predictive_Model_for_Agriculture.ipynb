{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to determine which soil characteristic (Nitrogen (N), Phosphorus (P), Potassium (K), or pH) is the best predictor for crop classification. Using a logistic regression model, we individually trained and tested models for each feature to measure their predictive power.\n"
      ],
      "metadata": {
        "id": "rWLenPZrrI8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlzgn2ygqGoj",
        "outputId": "b412459b-6efa-4daf-e006-25a848629dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score for N: 0.09149868209906838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score for P: 0.1476194290972821\n",
            "F1-score for K: 0.23896974566001802\n",
            "F1-score for ph: 0.0458225366614312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'K': 0.23896974566001802}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# All required libraries are imported here for you.\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset\n",
        "crops = pd.read_csv(\"soil_measures.csv\")\n",
        "\n",
        "# Check for missing values\n",
        "crops.isna().sum()\n",
        "\n",
        "# Check how many crops we have, i.e., multi-class target\n",
        "crops.crop.unique()\n",
        "\n",
        "# Split into feature and target sets\n",
        "X = crops.drop(columns=\"crop\")\n",
        "y = crops[\"crop\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create a dictionary to store the model performance for each feature\n",
        "feature_performance = {}\n",
        "\n",
        "# Train a logistic regression model for each feature\n",
        "for feature in [\"N\", \"P\", \"K\", \"ph\"]:\n",
        "    log_reg = LogisticRegression(multi_class=\"multinomial\")\n",
        "    log_reg.fit(X_train[[feature]], y_train)\n",
        "    y_pred = log_reg.predict(X_test[[feature]])\n",
        "\n",
        "    # Calculate F1 score, the harmonic mean of precision and recall\n",
        "    # Could also use balanced_accuracy_score\n",
        "    f1 = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    # Add feature-f1 score pairs to the dictionary\n",
        "    feature_performance[feature] = f1\n",
        "    print(f\"F1-score for {feature}: {f1}\")\n",
        "\n",
        "# K produced the best F1 score\n",
        "# Store in best_predictive_feature dictionary\n",
        "best_predictive_feature = {\"K\": feature_performance[\"K\"]}\n",
        "best_predictive_feature"
      ]
    }
  ]
}